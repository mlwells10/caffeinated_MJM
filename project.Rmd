---
title: "cherryB"
author: "Mina Mehdinia, Justin Valentine, Michael Wells"
date: "2022-10-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(tidyverse)
library(lubridate)
library(dplyr)
library(ggplot2)
#install.packages("plotly")
#devtools::install_github("dtkaplan/statisticalModeling")
#library(devtools)
library(statisticalModeling)
library(olsrr)
library(scatterplot3d)
library(plotly)
```

```{r}
Wdata <-  read.csv("newdata.csv")
Mdata <- read.csv("mendataclean.csv")

```

```{r}
Wdata$Age <- as.numeric(Wdata$Age )
wdat = Wdata[(!is.na(Wdata$Age))&(!is.na(Wdata$Time)),] #removing NA in Age and Time observation
wdat$Time = hms(wdat$Time) #convert time to hours, minutes, second
wdat$Time = as.numeric(seconds(wdat$Time))/60.0 #convert Time to minutes and to double
wdat = wdat[(!is.na(wdat$Time)),] #because of conversion to minutes some data will give NA, and because of that, we remove NA again
wdat

Mdata$Age <- as.numeric(Mdata$Age )
mdat = Mdata[(!is.na(Mdata$Age))&(!is.na(Mdata$Time)),] #removing NA in Age and Time observation
mdat$Time = hms(mdat$Time) #convert time to hours, minutes, second
mdat$Time = as.numeric(seconds(mdat$Time))/60.0 #convert Time to minutes and to double
mdat = mdat[(!is.na(mdat$Time)),] #because of conversion to minutes some data will give NA, and because of that, we remove NA again
mdat
```


```{r}
wdat <- wdat %>% 
  filter(!is.na(wdat$Age))
wdat

mdat <- mdat %>% 
  filter(!is.na(mdat$Age))
mdat
```


```{r}
glimpse(wdat)
```


```{r}
wdat <- arrange(wdat, Race)
mdat <- arrange(mdat, Race)

```

```{r}
load("cts_per_yeargender.Rdata")

ct_yrsex <- ct_yrsex[which(ct_yrsex$sex != "NA"), ]
ct_yrsex %>% filter(Year <= 2019) %>% 
ggplot(aes(x = Year, y = n))+
  geom_line(aes(color = factor(sex)))+
  scale_x_discrete(limits = c(1973:2019))+
  guides( color = guide_legend(title = "SEX"))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  ylab("Number of People")+
  labs(title = "Number of People in Each Year")
```
```{r}
age_group = case_when(wdat$Age <= 10 ~ "Age<=10", wdat$Age > 10 & wdat$Age <=20 ~ "10 < Age <= 20", wdat$Age > 20 & wdat$Age <=30 ~ "20 < Age <= 30", wdat$Age > 30 & wdat$Age <=40 ~ "30 < Age <= 40", wdat$Age > 40 & wdat$Age<=50 ~ "40 < Age <= 50", wdat$Age > 50 & wdat$Age <= 60 ~ "50 < Age <= 60",wdat$Age > 60 & wdat$Age <= 70 ~ "60 < Age <= 70",wdat$Age > 70 & wdat$Age <=80 ~ "70 < Age <= 80", wdat$Age > 80 ~ "Age > 80")

wdat  = wdat %>% mutate(age_group)

ggplot(wdat, aes(x = Race, fill = age_group))+
  geom_bar(position = "dodge")+ 
  scale_x_discrete(limits = c(1974:2022))+
  scale_fill_discrete(name = "Age Group")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  xlab("Year")+
  ylab("Count")+
  labs(title = "Range of Age in each Year for all Women")
```
```{r}
age_group = case_when(mdat$Age <= 10 ~ "Age<=10", mdat$Age > 10 & mdat$Age <=20 ~ "10 < Age <= 20", mdat$Age > 20 & mdat$Age <=30 ~ "20 < Age <= 30", mdat$Age > 30 & mdat$Age <=40 ~ "30 < Age <= 40", mdat$Age > 40 & mdat$Age<=50 ~ "40 < Age <= 50", mdat$Age > 50 & mdat$Age <= 60 ~ "50 < Age <= 60",mdat$Age > 60 & mdat$Age <= 70 ~ "60 < Age <= 70",mdat$Age > 70 & mdat$Age <=80 ~ "70 < Age <= 80", mdat$Age > 80 ~ "Age > 80")

mdat  = mdat %>% mutate(age_group)

ggplot(mdat, aes(x = Race, fill = age_group))+
  geom_bar(position = "dodge")+ 
  scale_x_discrete(limits = c(1973:2022))+
  scale_fill_discrete(name = "Age Group")+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  xlab("Year")+
  ylab("Count")+
  labs(title = "Range of Age in each Year for all Men")
```
```{r}
all_data <- rbind(wdat,mdat)
```
```{r}
all_data <- all_data %>% mutate(sex = (
strsplit(all_data$Division,"") %>% sapply( "[", 1 )))
all_data %>% filter(Time <2000) %>% 
ggplot(aes(fill = sex, colour = sex, group = sex))+
  geom_point(aes(x = Age, y = Time))+
  geom_smooth(aes(x = Age, y = Time))

```


```{r}
df_cleantown <- wdat[which(wdat$Hometown != "NR"), ]

df_cleantown$Hometown <- df_cleantown$Hometown %>% strsplit( ", " ) %>% sapply( "[", 1 )
df_cleantown <- df_cleantown %>% 
  filter(!is.na(df_cleantown$Hometown))

df_cleantown
```

```{r}
df_cleantown$Hometown <- tolower(df_cleantown$Hometown) #Returns the lowercase string.

all_states<-map_data("state")

library(ggplot2)
ggplot() +
  geom_polygon(data = all_states, aes( x = long, y = lat, group = group), fill="white", color="grey") +
  theme_void() +
  coord_map()

all_states = all_states %>%
  right_join(. , df_cleantown, by=c("region" ="Hometown"))
all_states <- arrange(all_states, Race)

all_states <- all_states %>% 
  filter(!is.na(all_states$long))
all_states

ggplot() +
  geom_polygon(data = all_states, aes( x = long, y = lat, group = group)) +
  theme_void() +
  coord_map()
```















```{r}
library(usmap)
states <- data.frame(df_cleantown$Hometown)

plot_usmap(regions = "states", labels = TRUE)+
  labs(title = "U.S. States",
       subtitle = "This is a blank map of the United States.") + 
  theme(panel.background=element_blank()) 
  
```

```{r}
#library(broom)
#spdf_fortified <- tidy(df_cleantown$Hometown)

#ggplot()+
#  geom_polygon(df_cleantown$Hometown)
```





```{r}
data = readr::read_csv("3139946.csv") #Loading the weather data and named it as data
head(data) #seeing the first six rows of the data
```



```{r}
#dates of all the races in consideration
race_dates <- c('1973/04/01', '1974/03/31', '1975/04/06', '1976/04/04', '1977/04/03', '1978/04/02', '1979/04/01', '1980/03/30', '1981/04/05', '1982/04/04', '1983/03/27', '1984/04/01', '1985/03/31', '1986/04/06', '1987/04/05', '1988/03/27', '1989/04/02', '1990/04/01', '1991/03/31', '1992/04/05', '1993/04/04', '1994/04/10', '1995/04/09', '1996/03/31', '1997/04/06', '1998/04/05', '1999/04/11', '2000/04/09', '2001/04/08', '2002/04/07', '2003/04/06', '2004/04/04', '2005/04/03', '2006/04/02', '2007/04/01', '2008/04/06', '2009/04/05', '2010/04/11', '2011/04/03', '2012/04/01', '2013/04/07', '2014/04/06' ,'2015/04/12', '2016/04/03', '2017/04/02', '2018/04/07', '2019/04/07')

race_dates=as.Date(race_dates, "%Y/%m/%d") #convert to data objects
dates = c(1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019) #create vector of year 
dates.df = data.frame(race_dates,dates) #create new data frame with Date and Year
colnames(dates.df) = c('DATE','Race')
```


```{r}
#using left join to add the year of first 10 races to the cherry blossom data frame
data_join_Race = newdata %>% left_join(dates.df, by = "Race")
head(data_join_Race)
```

```{r}
#using right join to add PRCP and TMIN columns from weather data frame to the cherry blossom data frame by the Date.
data_w <- data %>% select(DATE, PRCP, TMIN) %>% 
  right_join(data_join_Race, by = "DATE")
head(data_w)
```







```{r}
#needed to create a new column of times in integer seconds to run a model
data_t <- data_w %>% mutate(times = as.numeric(Time))
model_1 <- lm(times~0+Age, data=data_t)
summary(model_1)
```

Age is a significant predicter of run time

```{r}
model_2 <- lm(times~0+Division, data = data_t)
summary(model_2)
```

I think Division is probably a better predictor than Age. We cannot include both due to multicollinearity. 


```{r}
model_3 <- lm(times~ 0+PRCP, data=data_t )
summary(model_3)
```

Precipitation is a significant predictor. 



```{r}
model_4 <- lm(times~0+ TMIN, data=data_t )
summary(model_4)
```

Minimum temperature is a significant predictor



```{r}
model_f <- lm(times~0+Division +  PRCP , data=data_t)
summary(model_f)
```

The addition of TMIN was not significant. 

```{r}
confint(model_f)
```

The presence of precipitation lowers run time

```{r}
#lags the shit out of my computer
#plot_ly(data_t, x = ~Division, y = ~times, z = ~PRCP, type = "scatter3d", mode   = 'markers')
```

```{r}
anova(model_f)
```



```{r}
plot(model_f)
```


```{r}
new_inputs <- data.frame(Division = c('W2529'), PRCP = c(1.5))
#evaluate_model(model_f,new_inputs)
predict(model_f,new_inputs)
```

```{r}
fmodel(model_f, ~ Division + PRCP)
```

```{r}
unique(data_w$PRCP) #should probably trim some of these values since 0.0 and 0.01 are functionally the same
```




```{r}
PRCP <- data_w %>% filter(is.na(PRCP) == F)
new_inputs <- expand.grid(Division = unique(data_w$Division), PRCP = unique(PRCP$PRCP))
new_inputs
```

```{r}
#Predictions for every pair of division / PRCP
evaluate_model(model_f,new_inputs)
```
 
 