---
title: "R Coding Lab Part 2"
output: rmdformats::html_docco
---

# # Michael Wells, Justin Valentine, Mina Mehdinia

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Complete the following lab as a group. This document should exist in your GitHub repo while you're working on it. Your code should be heavily commented so someone reading your code can follow along easily. See the first code snippet below for an example of commented code.**

**Here's the catch: For any given problem, the person writing the code should not be the person commenting that code, and every person must both code AND comment at least one problem in this lab (you decide how to split the work). This will involve lots of pushing and pulling through Git, and you may have to resolve conflicts if you're not careful! Refer to last Thursday's class notes for details on conflict resolution.**


# Playing With Cherry Blossom Race Data

1) First load the data, which is saved as a .RData file called `CBdata.1_10.RData`. This is the first ten years' worth of Cherry Blossom Race data. Pull out the data associated with 1976 and store it as a data frame called `dat.76`. Remove the column `Pis/Tis` using a `dplyr` function. 


```{r import_data}
library(dplyr)
library(tidyr)
load("CBdata.1_10.RData" ) #Loading the cherry blossom data. (this is an example of a properly commented line of code)

dat.76 <- CBdata.1_10[[4]] #the 4th df is the df for year == 1976
dat.76 <- dat.76 %>% select(-`PiS/TiS`) #Removing the column 'PiS/TiS' since it is not needed
```


2) Use the `summarise()` function to find the mean and median recorded ages in 1976. 

```{r summary}
dat.76 %>% 
  filter(!is.na(Age)) %>% #We want to remove any NA values since they will affect the mean and median
  summarise(mean(Age), median(Age))
```


3) You might have noticed that a number of age values are missing (i.e. `NA`). Your next goal is to use `dplyr` to remove the data with missing age. This should not be a loop!  


```{r remove_missing_age}
dat.76 = dat.76 %>% filter(!is.na(Age)) #We can filter for all the age values that are NOT NA, then save that df as dat.76 effectively removing them. 

```


4) Last week you wrote a loop to combine all of the data from `CBdata.1_10` into one cleaned data frame. Use the function `bind_rows()` from `dplyr` to accomplish this same task. use the `?` command to look up documentation on functions you're not familar with like this: `?bind_rows`. Make sure your final data frame has neither the `Pis/Tis` column nor `NA` Age values.  
Use the `identical()` function to verify that the 1976 data in this larger cleaned data set is the same as the cleaned version of `dat.76`. 

```{r combine_dat}

dat <- bind_rows(CBdata.1_10) %>%
  filter(!is.na(Age)) %>% 
  select(-`PiS/TiS`) #similarly, removing the NA age values and the PiS/TiS column from all 10 df's

dat %>% filter(Year == 1976) %>% #to see if the two df's are identical we need to look at Year==1976
identical(dat.76)
```

5) Now that you have the combined data set for these 10 years, let's compare some basic results to what you found last week. Use piping and `dplyr` functions in your computations. 
a) Calculate the average of the recorded ages in 1976 and that same average over the entire `CBdata.1_10` data set, and make sure these numbers match the ones you found in Lab 1.  
```{r}
dat.76 %>% 
  summarise(mean(Age))
dat %>% 
  summarise(mean(Age)) #mean age in 1976 vs. mean age for every year in CBdata.1_10
```

b) Recall that the `CBdata.1_10` contains the first ten year's worth of cherry blossom race data. Compute the average participant age over the first five years and the average age over years 6-10, and make sure these numbers match the ones you found in Lab 1.  
```{r}
dat %>% 
  filter(Year >= 1973 & Year <=1977) %>%  
  summarise(mean(Age)) #Mean for ages between 1973 and 1977 inclusive
dat %>% 
  filter(Year >= 1978 & Year <=1982) %>% 
  summarise(mean(Age)) #Mean for ages between 1978 and 1982 inclusive
```



6) Let's now incorporate weather data into our cherry blossom data set. We will be dealing with multiple data sources, so this is a perfect opportunity to practice `join` skills...
a) use `readr()` to import the `weatherdat.csv` data. This is raw data recorded by a weather station in the Washington DC area. This particular data set contains daily summaries of various weather measurements. 
```{r}
data = readr::read_csv('weatherdat.csv')
head(data)
```

b) Open the `Rite_of_Spring_1973_2020-1.pdf` document, and record the dates of the first 10 races. Store this information in a vector or data frame.
```{r}
first_10 <- c('1973/04/01', '1974/03/31', '1975/04/06', '1976/04/04', '1977/04/03', '1978/04/02', '1979/04/01', '1980/03/30', '1981/04/05', '1982/04/04')
first_10=as.Date(first_10, "%Y/%m/%d")
dates = c(1973,1974,1975,1976,1977,1978,1979,1980,1981,1982)
dates.df = data.frame(first_10,dates)
colnames(dates.df) = c('DATE','Year')
```
c) Use a `join` function to add a date column to your cherry blossom data frame. Hints: (i) the `paste()` and `paste0` functions are useful for creating character vectors (ii) it would be useful for these dates to have the same format as those found in the weather data set...
```{r}
new.dat = dat %>% right_join(dates.df, by = "Year")
head(new.dat)
```


d) Use a `join` function to add precipitation `PRCP`  and minimum daily temperature `TMIN` columns to your cherry blossom data set.
```{r}
new_dat1 <- data %>% select(DATE, PRCP, TMIN) %>% 
  right_join(new.dat, by = "DATE")
head(new_dat1)
```

# Playing with the indoor positioning system data

The `IPS_sampledata` data set contains a fraction of the indoor positioning system data for 15 randomly sampled locations.This data set is loaded into memory using the chunk of R code below, complete the following exercises. 

```{r eval=T, echo=T}
# loads data set IPS_sampledata
load("IPS_portion.RData")
```

### Variable dictionary

- `time`: timestamp in milliseconds since midnight 01/01/1970 UTC

- `scanMac`: MAC address of the scanning device (this is a handheld device)

- `posX`, `posY` and `posZ`: the (x, y, z) physical coordinate of the scanning device

- `orientation`: degree orientation of the user carrying the scanning device in degrees

- `mac`: MAC address of an access point

- `signal`: signal strength in dBm (Decibel-milliwatts)

- `channel`: the channel frequency

- `type`: type of device (access point = 3, device in adhoc mode = 1)

### Let's clean up the data a bit

1. Apply the same `class` conversions you did last week to get these variables into the correct class type. Use `dplyr` functions and piping to complete this operation (there are many ways to do so). If you'd like to `mutate` multiple columns at once, the `across()` function might be useful!
```{r}
IPS_sampledata[,c(1,3:6,8:10)] <- IPS_sampledata %>% select(time, posX, posY, posZ, orientation, signal, channel, type) %>% sapply(as.numeric)
```

2. Because we only want data relative to access points, remove observations that correspond to any other type of device using `dplyr` functions.
```{r}
IPS_sampledata <- IPS_sampledata %>% filter(type != 1)
```


3. Last week you identified variables that provide redundant or no information. Remove them from the data frame using `dplyr` functions. 
```{r}
IPS_sampledata <- IPS_sampledata %>% select(-scanMac, -type, -channel)
```


4. Note that the `time` variable is in milliseconds.  Use `dplyr` to transform it into seconds and then convert its class into a time format using the function `as.POSIXct`.
```{r}
IPS_sampledata <- IPS_sampledata %>% mutate(time = time/1000)
IPS_sampledata$time <- IPS_sampledata$time %>%  as.POSIXct(format = "%S", origin = as.Date( "1970-01-01"), tzs = "PMS")
```


5. Convert this data set to a more wide format by creating one column for each access point, with each of those columns containing the corresponding signal strengths. Hint: you should end up with a data frame that has a lot fewer rows!  
Set this data set aside and use the long format data for the rest of the assignment
```{r}
IPS_sampledata %>% pivot_wider(names_from = mac, values_from = signal) #idk if this is right, prob not
```


### Examining the data more closely

1. Using grouping and `dplyr` functions, tally the  number of observations for all access points in the data. 
```{r}
IPS_sampledata %>% group_by(mac) %>% tally()
```

2. While the researchers did their best to clean their data, some noise was introduced by access points on other floors.  Based on the number of counts, identify and remove likely suspects for access points read by mistake, again using `dplyr` functions.
```{r}
#It looks like the first, 3rd and 5th might be erroneous
IPS_sampledata <- IPS_sampledata %>% filter(mac != '00:04:0e:5c:23:fc' & mac != '00:0f:a3:39:e0:4b' & mac != '00:0f:a3:39:e2:10')
IPS_sampledata
```


3.  The orientation of the hand-held device considered was supposed to be exactly set to the 8 angles from 0-315 in increments of 45 degrees (360 is equivalent to 0). However, in practice the measured orientations were close to the 8 expected but had some error.  Use the `case_when` function to recode the orientation values as one of 0, 45, 90, 135, 180, 225, 270, 315. Call the recoded orientation variable `rec_orient`.
```{r}
rec_orient =  case_when(IPS_sampledata$orientation >= 0.0 & IPS_sampledata$orientation <= 22.5 ~ 0.0,
                        IPS_sampledata$orientation > 22.5 & IPS_sampledata$orientation <= 67.5 ~ 45.0,
                        IPS_sampledata$orientation > 67.5 & IPS_sampledata$orientation <= 111.5 ~ 90.0,
                        IPS_sampledata$orientation > 111.5 & IPS_sampledata$orientation <= 157.5 ~ 135.0,
                        IPS_sampledata$orientation > 157.5 & IPS_sampledata$orientation <= 202.5 ~ 180.0,
                        IPS_sampledata$orientation > 202.5 & IPS_sampledata$orientation <= 247.5 ~ 225.0,          IPS_sampledata$orientation > 247.5 & IPS_sampledata$orientation <= 292.5 ~ 270.0,          IPS_sampledata$orientation > 292.5 ~ 315.0)
```


4. Last week you created the function `signal_summary` that takes as inputs a location (`posX`, `posY`, `posZ`), an orientation (`rec_orient`) and an access point id (`mac`).  The function identified and subset the rows in `IPS_sampledata` corresponding to this unique combination, then calculated and returned the mean and standard deviation for the corresponding signal strengths. You then used `lapply` to compute mean and standard deviation values for all combinations of location, orientation, and access point ID. 
Use piping,`summarise()`, and other `dplyr` functions to run this same computation without the use of loops or `lapply`. Compare your results with those from last week to confirm you're doing the right thing!
```{r}
IPS_data = IPS_sampledata %>% mutate(rec_orient)
signal_summary <- function(d){
  IPS_data %>% filter(posX==d[1],posY==d[2],posZ == d[3],rec_orient==d[4],mac==d[5]) %>% summarize(mean(signal), sd(signal))
}
#IPS_data %>% rowwise() %>% signal_summary(c(posX,posY,posZ,rec_orient,mac))
IPS_unique = IPS_data %>% distinct(posX,posY,posZ,rec_orient,mac)
IPS_unique[1:10,] %>% rowwise() %>% mutate(signal_summary(c(posX,posY,posZ,rec_orient,mac)))
```

